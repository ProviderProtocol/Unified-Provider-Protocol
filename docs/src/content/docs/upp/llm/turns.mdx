---
title: Turns
description: Turn structure and usage in UPP conversations.
---

import { Aside, Badge, Card, CardGrid } from '@astrojs/starlight/components';

# Turns

<Badge text="UPP-1.2.0" variant="note" />

## Turn Structure

A `Turn` represents the complete result of one inference call, including all messages produced during tool execution loops.

**Turn Structure:**

| Field | Type | Description |
|-------|------|-------------|
| `messages` | List&lt;Message&gt; | All messages produced, in chronological order |
| `response` | AssistantMessage | The final assistant response (convenience accessor) |
| `toolExecutions` | List&lt;ToolExecution&gt; | Tool executions that occurred |
| `usage` | TokenUsage | Aggregate token usage for the entire turn |
| `cycles` | Integer | Total number of inference cycles (1 + tool rounds) |
| `data` | Any? | Structured output data (if structure was provided) |

**ToolExecution Structure:**

| Field | Type | Description |
|-------|------|-------------|
| `toolName` | String | The tool that was called |
| `toolCallId` | String | Tool call ID |
| `arguments` | Map | Arguments passed to the tool |
| `result` | Any | Result returned by the tool |
| `isError` | Boolean | Whether the execution resulted in an error |
| `duration` | Integer | Execution duration in milliseconds |
| `approved` | Boolean? | Whether approval was required and granted |

**TokenUsage Structure:**

| Field | Type | Description |
|-------|------|-------------|
| `inputTokens` | Integer | Input tokens across all cycles |
| `outputTokens` | Integer | Output tokens across all cycles |
| `totalTokens` | Integer | Total tokens |
| `cacheReadTokens` | Integer | Tokens read from cache (cache hits). Returns 0 for providers that don't support cache metrics. |
| `cacheWriteTokens` | Integer | Tokens written to cache. Only Anthropic reports this; returns 0 for other providers. |
| `cycles` | List&lt;CycleUsage&gt;? | Per-cycle breakdown (if available) |

**CycleUsage Structure:**

| Field | Type | Description |
|-------|------|-------------|
| `inputTokens` | Integer | Input tokens for this cycle |
| `outputTokens` | Integer | Output tokens for this cycle |
| `cacheReadTokens` | Integer | Cache read tokens for this cycle |
| `cacheWriteTokens` | Integer | Cache write tokens for this cycle |

## Turn Usage

```text
claude = llm({
  model: anthropic("claude-haiku-4-20250514"),
  config: { apiKey: env.ANTHROPIC_API_KEY },
  system: "You are a helpful assistant.",
  tools: [getWeather]
})

history = []

// This turn might involve tool calls
turn = await claude.generate(history, "What is the weather in Tokyo?")

// Turn contains ALL messages from this inference:
// 1. UserMessage: "What is the weather in Tokyo?"
// 2. AssistantMessage: { toolCalls: [{ toolName: "getWeather", arguments: { location: "Tokyo" } }] }
// 3. ToolResultMessage: [{ result: "72°F, sunny" }]
// 4. AssistantMessage: "The weather in Tokyo is 72°F and sunny!"

print(turn.messages.length)  // 4
print(turn.response.text)    // "The weather in Tokyo is 72°F and sunny!"
print(turn.toolExecutions)   // [{ toolName: "getWeather", ... }]
print(turn.cycles)           // 2 (initial + after tool)

// Append all messages to history for next turn
history.push(...turn.messages)
```

## Turn Without Tool Calls

When no tools are called, the turn contains just the user input and assistant response:

```text
turn = await claude.generate("Hello!")

print(turn.messages.length)       // 2
print(turn.messages[0].type)      // "user"
print(turn.messages[1].type)      // "assistant"
print(turn.response.text)         // "Hello! How can I help you today?"
print(turn.response.hasToolCalls) // false
print(turn.toolExecutions)        // []
print(turn.cycles)                // 1
```