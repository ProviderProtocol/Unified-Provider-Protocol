---
title: Tools
description: UPP-1.2 tool definition, execution, and strategies.
---

import { Aside, Badge } from '@astrojs/starlight/components';

# Tools

<Badge text="UPP-1.2" variant="note" />

Tools allow LLMs to interact with external systems, execute code, and access real-time information. UPP uses JSON Schema for tool parameter definitions.

## Tool Definition

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | String | Yes | Tool name (must be unique within an llm() instance) |
| `description` | String | Yes | Human-readable description for the model |
| `parameters` | JSONSchema | Yes | JSON Schema defining parameters |
| `metadata` | ToolMetadata | No | Provider-specific metadata (e.g., cache control) |
| `run` | Function | Yes | Tool execution function |
| `approval` | Function | No | Optional approval handler for sensitive operations |

### ToolMetadata Structure

Provider-namespaced metadata for tools. Each provider defines its own metadata shape, enabling provider-specific features like prompt caching or strict schema validation without affecting other providers.

```text
{
  anthropic: { cache_control: { type: "ephemeral", ttl: "1h" } },
  openai: { strict: true }
}
```

| Provider | Namespace | Supported Options |
|----------|-----------|-------------------|
| Anthropic | `anthropic` | `cache_control: { type: "ephemeral", ttl?: "5m" \| "1h" }` |
| OpenAI | `openai` | `strict: boolean` (stricter JSON Schema validation) |

<Aside type="note" title="Provider Namespace Handling">
  Providers MUST ignore metadata namespaces they don't recognize. Tool metadata is passed through to the provider's native format where supported.
</Aside>

### JSONSchema Structure (for tool parameters)

```text
{
  type: "object",
  properties: {
    paramName: {
      type: "string" | "number" | "integer" | "boolean" | "array" | "object",
      description: "Parameter description",
      enum: [...],        // optional
      items: {...},       // for arrays
      properties: {...},  // for nested objects
      required: [...],    // for nested objects
      default: value      // optional
    }
  },
  required: ["paramName", ...]
}
```

## Tool Example

```text
getWeather = {
  name: "getWeather",
  description: "Get current weather for a location",
  parameters: {
    type: "object",
    properties: {
      location: {
        type: "string",
        description: "City name or coordinates"
      },
      units: {
        type: "string",
        enum: ["celsius", "fahrenheit"],
        default: "celsius"
      }
    },
    required: ["location"]
  },
  run: async (params) => {
    weather = await fetchWeather(params.location, params.units ?? "celsius")
    return weather.temp + "° " + params.units + ", " + weather.condition
  }
}

claude = llm({
  model: anthropic("claude-haiku-4-20250514"),
  config: { apiKey: env.ANTHROPIC_API_KEY },
  system: "You are a weather assistant.",
  tools: [getWeather]
})
```

## Tool Approval

For sensitive operations, tools can require approval:

```text
deleteFile = {
  name: "deleteFile",
  description: "Delete a file from the filesystem",
  parameters: {
    type: "object",
    properties: {
      path: { type: "string", description: "File path to delete" }
    },
    required: ["path"]
  },
  approval: async (params) => {
    // UI prompt, admin check, path validation, etc.
    return await promptUser("Allow deletion of " + params.path + "?")
  },
  run: async (params) => {
    await fs.unlink(params.path)
    return "Deleted " + params.path
  }
}
```

## Tool Execution Flow

By default, `llm()` handles tool execution automatically:

1. Model returns an `AssistantMessage` with `toolCalls`
2. If `approval` is defined, it's called first (rejected = error result sent to model)
3. Tool's `run` function is executed with arguments from the model
4. Result (or error) is sent back to the model as `ToolResultMessage`
5. Loop continues until model returns without tool calls OR max iterations reached

### Error Handling

- If `approval()` throws an exception, the exception propagates to the caller and aborts the generation
- If `approval()` returns `false`, an error result is sent to the model
- If the tool's `run` function throws, the error is caught and sent as an error result to the model

<Aside type="caution" title="No Argument Validation">
  `llm()` does NOT validate tool arguments against the JSON Schema. The schema is provided to the model to guide its output, but validation and sanitization of LLM-provided arguments is the responsibility of the tool implementation. Always treat tool arguments as untrusted input.
</Aside>

<Aside type="note" title="Structured Output Validation">
  Similarly, UPP does not validate [structured output](/spec/llm/structured/) responses against their schema. Schemas guide LLM behavior but validation is the application's responsibility in both cases.
</Aside>

## ToolUseStrategy

For custom control over tool execution, including input/output transformation:

| Field | Type | Description |
|-------|------|-------------|
| `maxIterations` | Integer | Maximum tool execution rounds (default: 10) |
| `onToolCall` | Function | Called when the model requests a tool call |
| `onBeforeCall` | Function | Called before tool execution; can skip or transform params |
| `onAfterCall` | Function | Called after tool execution; can transform result |
| `onError` | Function | Called on tool execution error |
| `onMaxIterations` | Function | Called when max iterations reached |

### BeforeCallResult Structure

| Field | Type | Description |
|-------|------|-------------|
| `proceed` | Boolean | Whether to proceed with tool execution |
| `params` | Any? | Transformed parameters to use (optional) |

### AfterCallResult Structure

| Field | Type | Description |
|-------|------|-------------|
| `result` | Any | Transformed result to return to the model |

### Hook Return Types

| Hook | Return Type | Behavior |
|------|-------------|----------|
| `onBeforeCall` | `false` | Skip execution |
| `onBeforeCall` | `true` | Proceed with original params |
| `onBeforeCall` | `BeforeCallResult` | Control execution and optionally transform params |
| `onAfterCall` | `void` | Use original result |
| `onAfterCall` | `AfterCallResult` | Transform result before returning to model |

### Strategy Example

```text
strategy = {
  maxIterations: 5,

  onBeforeCall: async (tool, params) => {
    print("Calling " + tool.name + " with", params)
    return true  // Allow execution with original params
  },

  onAfterCall: async (tool, params, result) => {
    await logToolUsage(tool.name, params, result)
    // Return void to use original result
  },

  onError: async (tool, params, error) => {
    await alertOps("Tool " + tool.name + " failed: " + error.message)
  },

  onMaxIterations: async (iterations) => {
    print("Tool loop hit max iterations:", iterations)
  }
}

claude = llm({
  model: anthropic("claude-haiku-4-20250514"),
  config: { apiKey: env.ANTHROPIC_API_KEY },
  tools: [getWeather, searchWeb],
  toolStrategy: strategy
})
```

### Input Transformation

Transform tool parameters before execution:

```text
strategy = {
  onBeforeCall: async (tool, params) => {
    if (tool.name == "search") {
      // Add default pagination
      return {
        proceed: true,
        params: { ...params, limit: 10, offset: 0 }
      }
    }
    // Proceed with original params for other tools
    return true
  }
}
```

### Output Transformation

Transform tool results before returning to the model:

```text
strategy = {
  onAfterCall: async (tool, params, result) => {
    if (tool.name == "fetch_data") {
      // Sanitize sensitive fields
      return { result: redactPII(result) }
    }
    if (tool.name == "get_users") {
      // Truncate large results
      return { result: result.slice(0, 100) }
    }
    // Return void to use original result
  }
}
```

### Combined Transformation

Input and output transformation can be combined:

```text
strategy = {
  onBeforeCall: async (tool, params) => {
    // Inject authentication
    if (tool.name == "api_call") {
      return {
        proceed: true,
        params: { ...params, authToken: getAuthToken() }
      }
    }
    return true
  },

  onAfterCall: async (tool, params, result) => {
    // Remove injected auth from logged result
    if (tool.name == "api_call") {
      return { result: { ...result, authToken: undefined } }
    }
  }
}
```

## Disabling Automatic Tool Execution

To handle tool calls manually:

```text
claude = llm({
  model: anthropic("claude-haiku-4-20250514"),
  config: { apiKey: env.ANTHROPIC_API_KEY },
  tools: [getWeather],
  toolStrategy: { maxIterations: 0 }  // Disable auto-execution
})

turn = await claude.generate([], "What is the weather?")

if (turn.response.hasToolCalls) {
  // Handle manually
  for toolCall in turn.response.toolCalls {
    print("Model wants to call:", toolCall.toolName)
    // Execute yourself, then continue conversation
  }
}
```

## Multiple Tool Calls

Models may request multiple tool calls in a single response. `llm()` executes them in parallel by default:

```text
claude = llm({
  model: anthropic("claude-haiku-4-20250514"),
  config: { apiKey: env.ANTHROPIC_API_KEY },
  tools: [getWeather, getTime]
})

// Model might call both tools simultaneously
turn = await claude.generate(
  "What is the weather and time in Tokyo and Paris?"
)

// turn.toolExecutions might contain 4 executions
// (weather + time for each city)
```

## Provider-Native Tools

Some providers offer **provider-native tools**—built-in capabilities that execute server-side rather than client-side. These differ fundamentally from UPP function tools:

| Aspect | UPP Function Tools | Provider-Native Tools |
|--------|-------------------|----------------------|
| Passed via | `tools` parameter in `llm()` | `params.tools` (pass-through) |
| Execution | Client-side via `run` function | Server-side by provider |
| Output | Returned by `run()`, sent back as `ToolResultMessage` | Incorporated into response content |
| Definition | Requires `name`, `description`, `parameters`, `run` | Provider-specific structure |

**Examples of provider-native tools:**

- **Web Search** - Search the web for current information
- **Code Interpreter** - Execute code in a sandboxed environment
- **Image Generation** - Generate images from text prompts
- **File Search** - Search through uploaded documents
- **Computer Use** - Interact with computer interfaces

### Usage Pattern

Provider-native tools are passed through the `params` object, not the `tools` array:

```text
import openai from "upp/openai"

// Provider-native tools go in params.tools
gpt = llm({
  model: openai("gpt-4o"),
  params: {
    tools: [
      { type: "web_search" },
      { type: "image_generation", quality: "high" }
    ]
  },
  // UPP function tools go here (can be used together)
  tools: [myCustomTool]
})
```

### Output Handling

Provider-native tool outputs SHOULD be transformed into standard UPP content blocks:

- Image generation results → `ImageBlock` in `AssistantMessage.content`
- Audio generation results → `AudioBlock` in `AssistantMessage.content`
- Text-based results (web search, code output) → Incorporated into text response

This ensures outputs are accessible via standard message accessors:

```text
turn = await gpt.generate("Generate an image of a sunset")

// Generated images are standard content blocks
images = turn.response.images  // List<ImageBlock>
firstImage = images[0]
```

### Provider Implementation

Providers offering native tools SHOULD:

1. **Document available tools** - List supported native tools and their configuration options
2. **Export helper constructors** - Provide ergonomic functions for creating tool configurations
3. **Transform outputs to content** - Convert tool outputs to standard `ContentBlock` types
4. **Preserve tool metadata** - Store provider-specific execution details in `metadata.{providerName}` if needed for multi-turn or debugging

```text
// Example: Provider exports tool helpers
import { tools } from "upp/openai"

gpt = llm({
  model: openai("gpt-4o"),
  params: {
    tools: [
      tools.webSearch({ search_context_size: "medium" }),
      tools.imageGeneration({ quality: "high", size: "1024x1024" })
    ]
  }
})
```

### Combining Tool Types

UPP function tools and provider-native tools can be used together. The provider is responsible for merging them correctly when sending requests:

```text
// Both tool types in one configuration
gpt = llm({
  model: openai("gpt-4o"),
  params: {
    tools: [tools.webSearch()]  // Provider-native
  },
  tools: [getWeather, saveNote]  // UPP function tools
})

// The model can use any available tool
turn = await gpt.generate("What's the weather in Paris and save it to my notes")
```

The `llm()` core handles UPP function tool execution automatically. Provider-native tools execute server-side and their results appear in the response.

## Provider Tool Reference

This section documents the built-in tools available for each provider. All tools are passed via the `params.builtInTools` array and have helper constructors in the provider's `tools` namespace.

### Anthropic Built-in Tools

Anthropic provides server-side tools for Claude models. Import via `import { tools } from "upp/anthropic"`.

| Tool | Constructor | Description | Pricing |
|------|-------------|-------------|---------|
| **Web Search** | `tools.webSearch()` | Search the web for real-time information | $10 per 1,000 tool invocations |
| **Computer Use** | `tools.computer()` | Control computer via mouse, keyboard, screenshots | Requires beta header |
| **Text Editor** | `tools.textEditor()` | View and edit files with str_replace operations | ~700 tokens overhead |
| **Bash** | `tools.bash()` | Execute shell commands | ~245 tokens overhead |
| **Code Execution** | `tools.codeExecution()` | Run Python in sandboxed container | $0.05 per container-hour |
| **Tool Search** | `tools.toolSearch()` | Dynamic tool catalog search (regex/BM25) | Token-based |

**Beta Header Requirements:**

Some Anthropic tools require a beta header to be included in the request:

| Tool | Beta Header | Status |
|------|-------------|--------|
| Web Search | None | GA |
| Computer Use | `computer-use-2025-01-24` | Beta |
| Text Editor | None | GA |
| Bash | None | GA |
| Code Execution | `code-execution-2025-08-25` | Beta |
| Tool Search | `advanced-tool-use-2025-11-20` | Beta |

**Web Search Example:**

```text
import { anthropic, tools } from "upp/anthropic"

claude = llm({
  model: anthropic("claude-sonnet-4-20250514"),
  params: {
    builtInTools: [
      tools.webSearch({
        max_uses: 5,  // Limit searches per request
        allowed_domains: ["wikipedia.org", "github.com"],
        user_location: {
          type: "approximate",
          city: "San Francisco",
          country: "US"
        }
      })
    ]
  }
})
```

**Code Execution Example (requires beta header):**

```text
claude = llm({
  model: anthropic("claude-sonnet-4-20250514"),
  config: {
    headers: { "anthropic-beta": "code-execution-2025-08-25" }
  },
  params: {
    builtInTools: [tools.codeExecution()],
    container: "container_id_from_previous_response"  // Reuse container
  }
})
```

**Computer Use (Beta):**

```text
claude = llm({
  model: anthropic("claude-sonnet-4-20250514"),
  config: {
    headers: { "anthropic-beta": "computer-use-2025-01-24" }
  },
  params: {
    builtInTools: [
      tools.computer({
        display_width_px: 1920,
        display_height_px: 1080,
        version: "20251124",  // Opus-optimized version
        enable_zoom: true
      })
    ]
  }
})
```

### Google Built-in Tools

Google provides server-side tools for Gemini models. Import via `import { tools } from "upp/google"`.

| Tool | Constructor | Description | Pricing |
|------|-------------|-------------|---------|
| **Google Search** | `tools.googleSearch()` | Grounding with Google Search | $14-35 per 1,000 queries |
| **Code Execution** | `tools.codeExecution()` | Execute Python code | Free |
| **URL Context** | `tools.urlContext()` | Fetch and analyze URLs | Token-based |
| **Google Maps** | `tools.googleMaps()` | Grounding with Google Maps | $25 per 1,000 queries |
| **File Search** | `tools.fileSearch()` | RAG search on document stores | Token-based |

**Google Search Example:**

```text
import { google, tools } from "upp/google"

gemini = llm({
  model: google("gemini-2.5-flash"),
  params: {
    builtInTools: [
      tools.googleSearch()
    ]
  }
})

// Grounding metadata available in response
turn = await gemini.generate("What's the latest news about AI?")
// turn.metadata.google.groundingMetadata contains search results
```

**Multiple Tools with Tool Config:**

```text
gemini = llm({
  model: google("gemini-2.5-flash"),
  params: {
    builtInTools: [
      tools.googleMaps({ enableWidget: true }),
      tools.codeExecution()
    ],
    toolConfig: {
      retrievalConfig: {
        latLng: { latitude: 40.758896, longitude: -73.985130 }
      }
    }
  }
})
```

<Aside type="note" title="Tool Limitations">
  File Search cannot be combined with other built-in tools.
</Aside>

### xAI Built-in Tools

xAI provides server-side tools for Grok models via the **Responses API only** (`api: 'responses'`). Import via `import { tools } from "upp/xai"`.

| Tool | Constructor | Description | Pricing |
|------|-------------|-------------|---------|
| **Web Search** | `tools.webSearch()` | Search the web for current information | $5 per 1,000 invocations |
| **X Search** | `tools.xSearch()` | Search X (Twitter) posts and profiles | $5 per 1,000 invocations |
| **Code Execution** | `tools.codeExecution()` | Execute Python in sandbox | $5 per 1,000 invocations |
| **File Search** | `tools.fileSearch()` | Search document collections | $2.50 per 1,000 invocations |
| **MCP** | `tools.mcp()` | Connect to remote MCP servers | Token-based only |

**Web Search and X Search Example:**

```text
import { xai, tools } from "upp/xai"

grok = llm({
  model: xai("grok-4", { api: "responses" }),
  params: {
    builtInTools: [
      tools.webSearch({
        allowed_domains: ["wikipedia.org"],
        enable_image_understanding: true
      }),
      tools.xSearch({
        allowed_x_handles: ["elonmusk", "xai"],
        from_date: "2025-01-01",
        enable_video_understanding: true
      })
    ]
  }
})
```

**Code Execution with Packages:**

```text
grok = llm({
  model: xai("grok-4", { api: "responses" }),
  params: {
    builtInTools: [
      tools.codeExecution({
        pip_packages: ["numpy", "pandas", "scipy"]
      })
    ]
  }
})
```

**MCP Server Connection:**

```text
grok = llm({
  model: xai("grok-4", { api: "responses" }),
  params: {
    builtInTools: [
      tools.mcp({
        server_url: "https://my-mcp-server.com/sse",
        server_label: "my_tools",
        allowed_tool_names: ["get_weather", "search_db"],
        authorization: "Bearer token123"
      })
    ]
  }
})
```

### OpenAI Built-in Tools

OpenAI provides built-in tools for GPT models via the **Responses API**. Import via `import { tools } from "upp/openai"`.

| Tool | Constructor | Description | Pricing |
|------|-------------|-------------|---------|
| **Web Search** | `tools.webSearch()` | Search the web for current information | Token-based |
| **Image Generation** | `tools.imageGeneration()` | Generate images from prompts | Per-image pricing |
| **Code Interpreter** | `tools.codeInterpreter()` | Execute Python in sandbox | Session-based |
| **File Search** | `tools.fileSearch()` | Search vector stores | Token-based |

**Web Search Example:**

```text
import { openai, tools } from "upp/openai"

gpt = llm({
  model: openai("gpt-4o"),
  params: {
    tools: [
      tools.webSearch({
        search_context_size: "medium",
        user_location: {
          type: "approximate",
          city: "Tokyo",
          country: "JP"
        }
      })
    ]
  }
})
```

**Image Generation Example:**

```text
gpt = llm({
  model: openai("gpt-4o"),
  params: {
    tools: [
      tools.imageGeneration({
        quality: "high",
        size: "1024x1024"
      })
    ]
  }
})

turn = await gpt.generate("Generate an image of a sunset over mountains")
// turn.response.images contains the generated ImageBlock
```

### OpenRouter

OpenRouter acts as a routing layer and does not provide its own built-in tools. Use the underlying provider's tools based on the model being used.

### Ollama

Ollama runs local models and does not provide server-side built-in tools. Use UPP function tools for client-side tool calling with local models.

## Complex Tool Example

```text
searchDatabase = {
  name: "searchDatabase",
  description: "Search the product database",
  parameters: {
    type: "object",
    properties: {
      query: {
        type: "string",
        description: "Search query"
      },
      filters: {
        type: "object",
        properties: {
          category: {
            type: "string",
            enum: ["electronics", "clothing", "home", "sports"]
          },
          minPrice: { type: "number" },
          maxPrice: { type: "number" },
          inStock: { type: "boolean" }
        }
      },
      limit: {
        type: "integer",
        description: "Maximum results to return",
        default: 10
      },
      sortBy: {
        type: "string",
        enum: ["relevance", "price_low", "price_high", "newest"],
        default: "relevance"
      }
    },
    required: ["query"]
  },
  run: async (params) => {
    results = await db.products.search({
      query: params.query,
      filters: params.filters ?? {},
      limit: params.limit ?? 10,
      sort: params.sortBy ?? "relevance"
    })
    return JSON.stringify(results)
  }
}
```

## Tool Security Considerations

<Aside type="caution" title="Security Warning">
  Tools execute arbitrary code based on LLM-provided arguments:

  - Tool arguments MUST be treated as untrusted input
  - Implementations MUST NOT automatically validate arguments against schema
  - Tool implementations SHOULD validate and sanitize inputs
  - Sensitive operations SHOULD use approval handlers
  - File system and network operations SHOULD be sandboxed where possible
</Aside>

### Safe Tool Implementation

```text
readFile = {
  name: "readFile",
  description: "Read a file from the allowed directory",
  parameters: {
    type: "object",
    properties: {
      path: { type: "string", description: "Relative file path" }
    },
    required: ["path"]
  },
  run: async (params) => {
    // Validate and sanitize path
    safePath = path.normalize(params.path)

    // Check for path traversal
    if (safePath.includes("..") || path.isAbsolute(safePath)) {
      throw new Error("Invalid path: must be relative without traversal")
    }

    // Restrict to allowed directory
    fullPath = path.join(ALLOWED_DIR, safePath)
    if (!fullPath.startsWith(ALLOWED_DIR)) {
      throw new Error("Path outside allowed directory")
    }

    // Check file exists and is readable
    if (!await fs.exists(fullPath)) {
      throw new Error("File not found")
    }

    return await fs.readFile(fullPath, "utf-8")
  }
}
```

## Capability Check

Providers that support tools MUST set `capabilities.tools` to `true`. If tools are provided but the capability is `false`, `llm()` MUST throw `UPPError` with code `INVALID_REQUEST`.
